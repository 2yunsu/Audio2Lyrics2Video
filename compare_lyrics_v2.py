import os
import openai
import re
import pandas as pd
from fuzzywuzzy import process
import unicodedata

# === ğŸ”§ ì„¤ì • ===
SRT_FOLDER = "./audio/transcriptions"
CSV_PATH = "50 Deutsche Lieder.csv"
OPENAI_API_KEY = ""  # ğŸ”‘ OpenAI API í‚¤ ì…ë ¥

# OpenAI API ì„¤ì •
openai.api_key = OPENAI_API_KEY

# CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv(CSV_PATH, encoding="utf-8")

# === ğŸ“Œ ì œëª© ì¶”ì¶œ í•¨ìˆ˜ ===
def extract_title(filename):
    """SRT íŒŒì¼ëª…ì—ì„œ ' - ' ì™€ '(' ì‚¬ì´ì˜ ë¬¸ìì—´ì„ ì¶”ì¶œí•˜ì—¬ Titleë¡œ ì‚¬ìš©"""
    match = re.search(r" - (.*?) \(", filename)
    return match.group(1).strip() if match else None

def find_best_match(title, title_list):
    best_match = process.extractOne(title, title_list)
    return best_match[0] if best_match else None

def normalize_text(text):
    """ìœ ë‹ˆì½”ë“œ ì •ê·œí™”ë¥¼ ì ìš©í•´ ë…ì¼ì–´ì˜ Ã¶, Ã¼, Ã¤ ê°™ì€ ë¬¸ìë¥¼ ASCIIë¡œ ë³€í™˜"""
    if pd.isna(text):  # NaN ê°’ ì²´í¬
        return ""  
    return unicodedata.normalize('NFKD', str(text)).encode('ASCII', 'ignore').decode('utf-8')

def clean_text(text):
    return re.sub(r"[^\w\s]", "", text).strip().lower()

def remove_duplicates(text):
    """ì¤‘ë³µëœ ë‹¨ì–´ ë˜ëŠ” ë¬¸ì¥ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    words = text.split()
    unique_words = []
    prev_word = None
    for word in words:
        if word != prev_word:
            unique_words.append(word)
        prev_word = word
    return " ".join(unique_words)

def transform_text_by_tokens(original_text, gt_lyrics):
    """ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ì›ë³¸ ê°€ì‚¬ ì¡°ê°ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¤‘ë³µ ì œê±°"""
    original_tokens = original_text.split()
    gt_lyrics_lines = gt_lyrics.split("\n")  # ì›ë³¸ ê°€ì‚¬ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°
    gt_phrases = [" ".join(line.split()[:4]) for line in gt_lyrics_lines]  # ë¬¸ë§¥ì„ ê³ ë ¤í•´ 4ë‹¨ì–´ì”© ë¬¶ê¸°
    breakpoint()
    transformed_tokens = []
    skip_next = False

    for i, token in enumerate(original_tokens):
        if skip_next:
            skip_next = False
            continue

        # í˜„ì¬ ë‹¨ì–´ + ë‹¤ìŒ ë‹¨ì–´ê¹Œì§€ í¬í•¨í•œ í”„ë ˆì´ì¦ˆ(ìµœëŒ€ 2ê·¸ë¨)
        phrase = " ".join(original_tokens[i:i+2])

        # ì „ì²´ ì›ë³¸ ê°€ì‚¬ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸êµ¬ ì°¾ê¸°
        best_match, score = process.extractOne(phrase, gt_phrases) if gt_phrases else (phrase, 0)

        if score >= 85:  # ë†’ì€ ìœ ì‚¬ë„ì¼ ë•Œ ë³€í™˜
            transformed_tokens.append(best_match)
            skip_next = True  # 2ê·¸ë¨ì„ ë§¤ì¹­í–ˆìœ¼ë¯€ë¡œ ë‹¤ìŒ ë‹¨ì–´ëŠ” ê±´ë„ˆë›´ë‹¤
        else:
            best_match, score = process.extractOne(token, gt_lyrics_lines) if gt_lyrics_lines else (token, 0)
            transformed_tokens.append(best_match if score >= 80 else token)

    # ì¤‘ë³µ ì œê±°
    transformed_text = remove_duplicates(" ".join(transformed_tokens))
    return transformed_text

def read_srt(srt_path):
    """SRT íŒŒì¼ì„ ì½ì–´ì„œ (ë²ˆí˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, ë¬¸ì¥) ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    with open(srt_path, "r", encoding="utf-8") as f:
        content = f.read()

    entries = []
    blocks = content.strip().split("\n\n")  # ë¹ˆ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ ë‚˜ëˆ„ê¸°
    for block in blocks:
        lines = block.split("\n")
        if len(lines) >= 3:
            num = lines[0]
            timestamp = lines[1]
            text = " ".join(lines[2:])
            entries.append((num, timestamp, text))
    return entries

# # === ğŸ“Œ SRT íŒŒì¼ ì½ê¸° ===
# def read_srt(file_path):
#     """SRT íŒŒì¼ì„ ì½ì–´ì„œ (ë²ˆí˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, ê°€ì‚¬) ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
#     with open(file_path, "r", encoding="utf-8") as f:
#         lines = f.readlines()
    
#     srt_entries = []
#     i = 0
#     while i < len(lines):
#         if lines[i].strip().isdigit():  # ë²ˆí˜¸
#             num = int(lines[i].strip())
#             i += 1
#             timestamp = lines[i].strip()  # íƒ€ì„ìŠ¤íƒ¬í”„
#             i += 1
#             lyrics = []
#             while i < len(lines) and lines[i].strip() and "-->" not in lines[i]:
#                 lyrics.append(lines[i].strip())
#                 i += 1
#             original_lyrics = " ".join(lyrics)
#             srt_entries.append((num, timestamp, original_lyrics))
#         i += 1
    
#     return srt_entries


# # === ğŸ”¥ GPT ë³€í™˜ í•¨ìˆ˜ ===
# def convert_lyrics_with_gpt(original_lyrics, gt_lyrics, gt_kr_lyrics):
#     """ChatGPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ SRT ê°€ì‚¬ë¥¼ ë³€í™˜"""
#     prompt = f"""
#     {original_lyrics}.srtëŠ” Audio to Text ëª¨ë¸ë¡œ ì¶”ì¶œí•œ ê°€ì‚¬ì´ê³ , {gt_lyrics}ëŠ” ì›ë¬¸ ê°€ì‚¬, {gt_kr_lyrics}ëŠ” í•œêµ­ì–´ ë²ˆì—­ ê°€ì‚¬ì•¼.
#     {original_lyrics}.srt ê°€ì‚¬ì˜ ì‹œê°„ëŒ€ë³„ ê°€ì‚¬ë¥¼ ì‹œê°„ ì •ë³´ëŠ” ìœ ì§€í•œ ì±„ {gt_lyrics}ì— ëŒ€ì‘í•˜ëŠ” ë…ì¼ì–´ ê°€ì‚¬ë¡œ ë°”ê¾¸ì–´ì£¼ê³ ,
#     ê° ë…ì¼ì–´ ê°€ì‚¬ ì˜¤ë¥¸ìª½ì— "/n {gt_kr_lyrics}"ë¥¼ ì¶”ê°€í•´ì¤˜.
#     """
    
#     response = openai.ChatCompletion.create(
#         model="gpt-4",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.7
#     )
    
#     return response["choices"][0]["message"]["content"].strip()

# === ğŸ” í´ë” ë‚´ ëª¨ë“  SRT íŒŒì¼ ë³€í™˜ ===
for srt_file in os.listdir(SRT_FOLDER):
    if srt_file.endswith(".srt"):
        srt_path = os.path.join(SRT_FOLDER, srt_file)
        title = extract_title(srt_file)
        print("title:", title)
        
        if title:
            # matched_row = df[df["Title"] == title]
            # matched_row = df[df["Title"].str.strip().str.lower() == title.strip().lower()]
            normalized_title = normalize_text(title)  # íŒŒì¼ ì´ë¦„ì„ ë³€í™˜
            df["Normalized_Title"] = df["Title"].apply(normalize_text)  # CSVì˜ Title ì—´ ë³€í™˜
            best_match, score, _ = process.extractOne(title, df["Normalized_Title"])
            if score >= 80:
                matched_row = df[df["Normalized_Title"] == best_match]
            else:
                matched_row = pd.DataFrame()  # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¹ˆ DataFrame ë°˜í™˜
            # matched_row = df[df["Normalized_Title"] == normalized_title]  # ë³€í™˜ëœ ë¬¸ìì—´ë¡œ ë¹„êµ


            if not matched_row.empty:
                srt_entries = read_srt(srt_path)
                gt_lyrics = matched_row.iloc[0]["Lyrics"]
                gt_kr_lyrics = matched_row.iloc[0]["Ko_lyrics"]

                # ë³€í™˜ëœ ê°€ì‚¬ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                new_srt_content = []
                for num, timestamp, original_text in srt_entries:
                    # ì „ì²˜ë¦¬ ì ìš©
                    # cleaned_original = clean_text(original_text)
                    # cleaned_lyrics = [clean_text(line) for line in gt_lyrics]

                    # transformed_text = convert_lyrics_with_gpt(original_text, gt_lyrics, gt_kr_lyrics)
                    # transformed_text = process.extractOne(original_text, gt_lyrics.split("\n"))[0]
                    # breakpoint()
                    transformed_text = transform_text_by_tokens(original_text, gt_lyrics)
                    new_srt_content.append(f"{num}\n{timestamp}\n{transformed_text}\n")
                # ë³€í™˜ëœ SRT ì €ì¥
                new_srt_path = os.path.join("./audio/converted", srt_file)
                with open(new_srt_path, "w", encoding="utf-8") as f:
                    f.write("\n".join(new_srt_content))

                print(f"âœ… ë³€í™˜ ì™„ë£Œ: {new_srt_path}")
            else:
                print(f"âš ï¸ {title}: CSVì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")

print("\nğŸ‰ ëª¨ë“  ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
